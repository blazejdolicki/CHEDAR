10/19/2021 14:09:49 - WARNING - __main__ -   device: cuda, n_gpu: 1
10/19/2021 14:09:52 - INFO - __main__ -   Building index
10/19/2021 14:09:53 - INFO - transformers.configuration_utils -   loading configuration file checkpoints/convdr-multi-cast19-4/config.json
10/19/2021 14:09:53 - INFO - transformers.configuration_utils -   Model config {
  "_num_labels": 2,
  "architectures": [
    "RobertaDot_NLL_LN"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": 0,
  "decoder_start_token_id": null,
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "finetuning_task": "MSMarco",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 514,
  "min_length": 0,
  "model_type": "roberta",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

10/19/2021 14:09:53 - INFO - transformers.tokenization_utils -   Model name 'checkpoints/convdr-multi-cast19-4' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'checkpoints/convdr-multi-cast19-4' is a path or url to a directory containing tokenizer files.
10/19/2021 14:09:53 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/vocab.json
10/19/2021 14:09:53 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/merges.txt
10/19/2021 14:09:53 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/added_tokens.json
10/19/2021 14:09:53 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/special_tokens_map.json
10/19/2021 14:09:53 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/tokenizer_config.json
10/19/2021 14:09:55 - INFO - transformers.modeling_utils -   loading weights file checkpoints/convdr-multi-cast19-4/pytorch_model.bin
10/19/2021 14:10:07 - INFO - __main__ -   Training/evaluation parameters Namespace(ann_data_dir='/project/gpuuva006/CAST19_ANCE_embeddings', cache_dir='../ann_cache_dir', cross_validate=False, device=device(type='cuda'), eval_file='datasets/cast-19/eval_topics.jsonl', fold=-1, max_concat_length=256, max_query_length=64, model_path='checkpoints/convdr-multi-cast19-4', model_type='rdot_nll', n_gpu=1, no_cuda=False, output_file='results/cast-19/multi.jsonl', output_query_type='raw', output_trec_file='results/cast-19/multi.trec', per_gpu_eval_batch_size=8, processed_data_dir='/project/gpuuva006/team3/cast-tokenized/', qrels='datasets/cast-19/qrels.tsv', query='no_res', raw_data_dir='datasets/cast-19', seed=42, top_n=100, use_gpu=True)
10/19/2021 14:10:07 - INFO - __main__ -   ***** Running evaluation *****
10/19/2021 14:10:07 - INFO - __main__ -     Num examples = 479
10/19/2021 14:10:07 - INFO - __main__ -     Instantaneous batch size per GPU = 8
10/19/2021 14:10:12 - INFO - __main__ -   Loading passage reps - block 0 part 0
10/19/2021 14:10:23 - INFO - __main__ -   Loading passage reps - block 0 part 1
10/19/2021 14:10:38 - INFO - __main__ -   Loading passage reps - block 0 part 2
10/19/2021 14:10:55 - INFO - __main__ -   Loading passage reps - block 0 part 3
10/19/2021 14:11:12 - INFO - __main__ -   Loading passage reps - block 1 part 0
10/19/2021 14:11:29 - INFO - __main__ -   Loading passage reps - block 1 part 1
10/19/2021 14:11:46 - INFO - __main__ -   Loading passage reps - block 1 part 2
10/19/2021 14:12:03 - INFO - __main__ -   Loading passage reps - block 1 part 3
10/19/2021 14:12:21 - INFO - __main__ -   Loading passage reps - block 2 part 0
10/19/2021 14:12:38 - INFO - __main__ -   Loading passage reps - block 2 part 1
10/19/2021 14:12:55 - INFO - __main__ -   Loading passage reps - block 2 part 2
10/19/2021 14:13:12 - INFO - __main__ -   Loading passage reps - block 2 part 3
10/19/2021 14:13:29 - INFO - __main__ -   Loading passage reps - block 3 part 0
10/19/2021 14:13:48 - INFO - __main__ -   Loading passage reps - block 3 part 1
10/19/2021 14:14:04 - INFO - __main__ -   Loading passage reps - block 3 part 2
10/19/2021 14:14:21 - INFO - __main__ -   Loading passage reps - block 3 part 3
10/19/2021 14:14:38 - INFO - __main__ -   start EvalDevQuery...
10/19/2021 14:14:38 - INFO - __main__ -   Reading queries and passages...
offset2pid first 10 elements [10000000, 10000032, 10000064, 10000096, 10000128, 10000160, 10000192, 10000224, 10000256, 10000288]
Using mean: False
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23920440673828125, 'data': 479, 'per_query': 0.0004993828950694807}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.2364952564239502, 'data': 479, 'per_query': 0.0004937270489017749}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23933672904968262, 'data': 479, 'per_query': 0.0004996591420661432}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.2533087730407715, 'data': 479, 'per_query': 0.0005288283362020282}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23828959465026855, 'data': 479, 'per_query': 0.0004974730577249866}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23805499076843262, 'data': 479, 'per_query': 0.0004969832792660389}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23984622955322266, 'data': 479, 'per_query': 0.0005007228174388782}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.23926019668579102, 'data': 479, 'per_query': 0.0004994993667761816}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.24855732917785645, 'data': 479, 'per_query': 0.0005189088291813287}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.23988866806030273, 'data': 479, 'per_query': 0.0005008114155747447}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.23971772193908691, 'data': 479, 'per_query': 0.0005004545343195969}
passage embedding shape: (2401864, 768)
query embedding shape: (479, 768)
{'total': 0.2563655376434326, 'data': 479, 'per_query': 0.0005352098906961015}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.2398083209991455, 'data': 479, 'per_query': 0.0005006436764074019}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.2405073642730713, 'data': 479, 'per_query': 0.0005021030569375183}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.25049757957458496, 'data': 479, 'per_query': 0.0005229594563143736}
passage embedding shape: (2401864, 768)
query embedding shape: (479, 768)
{'total': 0.23927021026611328, 'data': 479, 'per_query': 0.0004995202719543074}
[[4578361  939931 2214694 ... 5982775 8954975 3567019]
 [4564873 7169817 2366086 ... 8283159 1785583 8327599]
 [9554260 4564873 9205430 ... 9321739 9478139 3466291]
 ...
 [7258179  748786 1820557 ...  713987 6330187  551087]
 [7258179  748786 6422764 ...   22383   36427 8607547]
 [7258179  748786 6422764 ...  231367   22383 6089067]]
bad passage
bad passage
bad passage
bad passage
bad passage
bad passage
bad passage
bad passage
