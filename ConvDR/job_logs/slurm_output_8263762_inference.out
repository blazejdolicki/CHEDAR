10/20/2021 11:11:04 - WARNING - __main__ -   device: cuda, n_gpu: 1
10/20/2021 11:11:06 - INFO - __main__ -   Building index
10/20/2021 11:11:07 - INFO - transformers.configuration_utils -   loading configuration file checkpoints/convdr-multi-cast19-4/config.json
10/20/2021 11:11:07 - INFO - transformers.configuration_utils -   Model config {
  "_num_labels": 2,
  "architectures": [
    "RobertaDot_NLL_LN"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": 0,
  "decoder_start_token_id": null,
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "finetuning_task": "MSMarco",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 514,
  "min_length": 0,
  "model_type": "roberta",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

10/20/2021 11:11:07 - INFO - transformers.tokenization_utils -   Model name 'checkpoints/convdr-multi-cast19-4' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'checkpoints/convdr-multi-cast19-4' is a path or url to a directory containing tokenizer files.
10/20/2021 11:11:07 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/vocab.json
10/20/2021 11:11:07 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/merges.txt
10/20/2021 11:11:07 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/added_tokens.json
10/20/2021 11:11:07 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/special_tokens_map.json
10/20/2021 11:11:07 - INFO - transformers.tokenization_utils -   loading file checkpoints/convdr-multi-cast19-4/tokenizer_config.json
10/20/2021 11:11:09 - INFO - transformers.modeling_utils -   loading weights file checkpoints/convdr-multi-cast19-4/pytorch_model.bin
10/20/2021 11:11:21 - INFO - __main__ -   Training/evaluation parameters Namespace(ann_data_dir='/project/gpuuva006/CAST19_ANCE_embeddings', cache_dir='../ann_cache_dir', cross_validate=False, device=device(type='cuda'), eval_file='datasets/cast-19/eval_topics.jsonl', fold=-1, max_concat_length=256, max_query_length=64, model_path='checkpoints/convdr-multi-cast19-4', model_type='rdot_nll', n_gpu=1, no_cuda=False, output_file='results/cast-19/multi.jsonl', output_query_type='raw', output_trec_file='results/cast-19/multi.trec', per_gpu_eval_batch_size=8, processed_data_dir='/project/gpuuva006/team3/cast-tokenized/', qrels='datasets/cast-19/qrels.tsv', query='no_res', raw_data_dir='datasets/cast-19', seed=42, top_n=100, use_gpu=True)
10/20/2021 11:11:22 - INFO - __main__ -   ***** Running evaluation *****
10/20/2021 11:11:22 - INFO - __main__ -     Num examples = 479
10/20/2021 11:11:22 - INFO - __main__ -     Instantaneous batch size per GPU = 8
10/20/2021 11:11:26 - INFO - __main__ -   Loading passage reps - block 0 part 0
10/20/2021 11:11:37 - INFO - __main__ -   Loading passage reps - block 0 part 1
10/20/2021 11:11:48 - INFO - __main__ -   Loading passage reps - block 0 part 2
10/20/2021 11:11:58 - INFO - __main__ -   Loading passage reps - block 0 part 3
10/20/2021 11:12:09 - INFO - __main__ -   Loading passage reps - block 1 part 0
10/20/2021 11:12:20 - INFO - __main__ -   Loading passage reps - block 1 part 1
10/20/2021 11:12:35 - INFO - __main__ -   Loading passage reps - block 1 part 2
10/20/2021 11:12:52 - INFO - __main__ -   Loading passage reps - block 1 part 3
10/20/2021 11:13:09 - INFO - __main__ -   Loading passage reps - block 2 part 0
10/20/2021 11:13:26 - INFO - __main__ -   Loading passage reps - block 2 part 1
10/20/2021 11:13:43 - INFO - __main__ -   Loading passage reps - block 2 part 2
10/20/2021 11:14:00 - INFO - __main__ -   Loading passage reps - block 2 part 3
10/20/2021 11:14:17 - INFO - __main__ -   Loading passage reps - block 3 part 0
10/20/2021 11:14:36 - INFO - __main__ -   Loading passage reps - block 3 part 1
10/20/2021 11:14:52 - INFO - __main__ -   Loading passage reps - block 3 part 2
10/20/2021 11:15:09 - INFO - __main__ -   Loading passage reps - block 3 part 3
10/20/2021 11:15:26 - INFO - __main__ -   start EvalDevQuery...
10/20/2021 11:15:26 - INFO - __main__ -   Reading queries and passages...
offset2pid first 10 elements [10000000, 10000032, 10000064, 10000096, 10000128, 10000160, 10000192, 10000224, 10000256, 10000288]
Using mean: False
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.2519104480743408, 'data': 479, 'per_query': 0.0005259090773994589}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23928403854370117, 'data': 479, 'per_query': 0.0004995491410098146}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23825907707214355, 'data': 479, 'per_query': 0.0004974093467059364}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.23879766464233398, 'data': 479, 'per_query': 0.0004985337466437035}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.2551760673522949, 'data': 479, 'per_query': 0.0005327266541801564}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23647570610046387, 'data': 479, 'per_query': 0.000493686234030196}
passage embedding shape: (2401866, 768)
query embedding shape: (479, 768)
{'total': 0.23758935928344727, 'data': 479, 'per_query': 0.0004960111884831885}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.25599193572998047, 'data': 479, 'per_query': 0.000534429928455074}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.2379758358001709, 'data': 479, 'per_query': 0.0004968180288103777}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.23795580863952637, 'data': 479, 'per_query': 0.000496776218454126}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.2514948844909668, 'data': 479, 'per_query': 0.0005250415125072376}
passage embedding shape: (2401864, 768)
query embedding shape: (479, 768)
{'total': 0.2367992401123047, 'data': 479, 'per_query': 0.0004943616703805944}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.2502555847167969, 'data': 479, 'per_query': 0.0005224542478429997}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.2406156063079834, 'data': 479, 'per_query': 0.0005023290319582117}
passage embedding shape: (2401865, 768)
query embedding shape: (479, 768)
{'total': 0.23892807960510254, 'data': 479, 'per_query': 0.0004988060117016754}
passage embedding shape: (2401864, 768)
query embedding shape: (479, 768)
{'total': 0.25473690032958984, 'data': 479, 'per_query': 0.0005318098127966385}
[[4578361  939931 2214694 ... 5982775 8954975 3567019]
 [4564873 7169817 2366086 ... 8283159 1785583 8327599]
 [9554260 4564873 9205430 ... 9321739 9478139 3466291]
 ...
 [7258179  748786 1820557 ...  713987 6330187  551087]
 [7258179  748786 6422764 ...   22383   36427 8607547]
 [7258179  748786 6422764 ...  231367   22383 6089067]]
bad pid
